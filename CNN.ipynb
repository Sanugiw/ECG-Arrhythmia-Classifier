{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsyhWgFjK8-Y"
      },
      "source": [
        "## **ECG Arrhythmia Classification with CNN and Interactive Dashboard**\n",
        "\n",
        "Electrocardiography (ECG) is a non-invasive technique that records the electrical activity of the heart over time. The ECG waveform reflects the coordinated depolarization and repolarization of cardiac muscle cells, mediated by the heart’s conduction system.\n",
        "\n",
        "### **Anatomical and Physiological Basis**\n",
        "\n",
        "The heart’s conduction system ensures rhythmic and synchronized contractions:\n",
        "\n",
        "* **Sinoatrial (SA) Node** – The natural pacemaker, located in the right atrium, initiates the electrical impulse.\n",
        "* **Atrial Muscle** – Conducts the impulse across both atria, producing the **P wave** (atrial depolarization).\n",
        "* **Atrioventricular (AV) Node** – Delays the impulse to allow ventricular filling, seen in the **PR segment**.\n",
        "* **Bundle of His & Bundle Branches** – Transmit the signal through the interventricular septum.\n",
        "* **Purkinje Fibers** – Rapidly deliver the impulse to ventricular myocardium, generating the **QRS complex** (ventricular depolarization) followed by the **T wave** (ventricular repolarization).\n",
        "\n",
        "### **Arrhythmias and ECG Changes**\n",
        "\n",
        "Arrhythmias occur when the impulse generation or conduction pathway is altered:\n",
        "\n",
        "* **Normal beat (N)** – Regular SA node rhythm with intact conduction.\n",
        "* **Ventricular ectopic beat (VEB)** – Premature ventricular depolarization from an abnormal focus in the ventricles, often producing a wide QRS complex.\n",
        "* **Supraventricular ectopic beat (SVEB)** – Originates above the ventricles (atria or AV node) and alters P-wave morphology with a narrow QRS.\n",
        "* **Fusion beat (F)** – A hybrid waveform from simultaneous normal and ectopic activation.\n",
        "\n",
        "These morphological differences are directly tied to the anatomical site of origin, making ECG classification both clinically relevant and physiologically interpretable.\n",
        "\n",
        "### **Project Objective**\n",
        "\n",
        "In this project, we develop a **Convolutional Neural Network (CNN)** model to classify ECG beats into different arrhythmia types using the MIT-BIH Arrhythmia Database. The model automatically learns morphological features such as P-wave shape, QRS width, and ST-T segment variations that correspond to underlying conduction abnormalities.\n",
        "\n",
        "To make the results accessible and interpretable, we integrate the trained model into a **Streamlit-based interactive dashboard** that allows users to:\n",
        "\n",
        "* Upload ECG files or explore sample beats\n",
        "* View the raw waveform and detected beats\n",
        "* See classification results with confidence scores\n",
        "* Explore explainability visualizations (e.g., Grad-CAM) mapping model attention to specific waveform regions\n",
        "* Connect waveform changes to anatomical and physiological causes\n",
        "\n",
        "This combination of deep learning, interactive visualization, and anatomical context bridges the gap between machine intelligence and clinical reasoning.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_jFOesPPf2I",
        "outputId": "cb27efab-a917-4253-f488-34212a0b7aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder structure ready.\n",
            "MIT-BIH records downloaded.\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 1. Create folder structure\n",
        "# ================================================================\n",
        "import os\n",
        "\n",
        "folders = [\n",
        "    \"data/raw\",\n",
        "    \"data/processed\",\n",
        "    \"models\",\n",
        "    \"src/data\",\n",
        "    \"src/models\",\n",
        "    \"app\"\n",
        "]\n",
        "for f in folders:\n",
        "    os.makedirs(f, exist_ok=True)\n",
        "\n",
        "print(\"Folder structure ready.\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 2. Download MIT-BIH Arrhythmia Database (selected records)\n",
        "# ================================================================\n",
        "import wfdb\n",
        "\n",
        "record_ids = [\n",
        "    \"100\", \"101\", \"102\", \"103\", \"104\", \"105\", \"106\", \"107\", \"108\",\n",
        "    \"109\", \"111\", \"112\", \"113\", \"114\", \"115\", \"116\", \"117\", \"118\",\n",
        "    \"119\", \"121\", \"122\", \"123\", \"124\", \"200\"\n",
        "]\n",
        "\n",
        "for rec in record_ids:\n",
        "    rec_path = os.path.join(\"data/raw\", rec)\n",
        "    if not os.path.exists(rec_path):\n",
        "        print(f\"⬇Downloading record {rec}...\")\n",
        "        wfdb.dl_database(\"mitdb\", rec_path, records=[rec])\n",
        "print(\"MIT-BIH records downloaded.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0szKtOQQQrf"
      },
      "source": [
        "1. Data Preparation and Labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTZIMTrJQOvo",
        "outputId": "5ff108ca-9464-4a28-eb82-3fcfb5c2506f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100: 2272 beats extracted\n",
            " 101: 1873 beats extracted\n",
            " 102: 2191 beats extracted\n",
            " 103: 2089 beats extracted\n",
            " 104: 2309 beats extracted\n",
            " 105: 2690 beats extracted\n",
            " 106: 2098 beats extracted\n",
            " 107: 2139 beats extracted\n",
            " 108: 1823 beats extracted\n",
            " 109: 2533 beats extracted\n",
            " 111: 2132 beats extracted\n",
            " 112: 2548 beats extracted\n",
            " 113: 1794 beats extracted\n",
            " 114: 1889 beats extracted\n",
            " 115: 1960 beats extracted\n",
            " 116: 2420 beats extracted\n",
            " 117: 1538 beats extracted\n",
            " 118: 2299 beats extracted\n",
            " 119: 2093 beats extracted\n",
            " 121: 1874 beats extracted\n",
            " 122: 2477 beats extracted\n",
            " 123: 1517 beats extracted\n",
            " 124: 1633 beats extracted\n",
            " 200: 2790 beats extracted\n",
            "\n",
            " Total beats extracted: 50981\n",
            "Label distribution: Counter({np.str_('N'): 33277, np.str_('/'): 5485, np.str_('L'): 4614, np.str_('R'): 3695, np.str_('V'): 2172, np.str_('f'): 722, np.str_('+'): 355, np.str_('~'): 321, np.str_('A'): 185, np.str_('|'): 51, np.str_('J'): 31, np.str_('Q'): 25, np.str_('x'): 21, np.str_('F'): 15, np.str_('j'): 6, np.str_('a'): 6})\n",
            "Balancing dataset to 6 samples per class...\n",
            "Final balanced dataset: 96 beats\n",
            "Final label distribution: Counter({np.str_('+'): 6, np.str_('/'): 6, np.str_('A'): 6, np.str_('F'): 6, np.str_('J'): 6, np.str_('L'): 6, np.str_('N'): 6, np.str_('Q'): 6, np.str_('R'): 6, np.str_('V'): 6, np.str_('a'): 6, np.str_('f'): 6, np.str_('j'): 6, np.str_('x'): 6, np.str_('|'): 6, np.str_('~'): 6})\n",
            "Data saved in data/processed/ (beats.npy & labels.npy)\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Preprocessing functions\n",
        "# ================================================================\n",
        "import numpy as np\n",
        "import neurokit2 as nk\n",
        "from scipy.signal import butter, filtfilt\n",
        "from collections import Counter\n",
        "from sklearn.utils import resample\n",
        "\n",
        "def bandpass_filter(signal, fs, lowcut=0.5, highcut=40.0, order=4):\n",
        "    \"\"\"Bandpass filter for ECG signal.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "\n",
        "def preprocess_ecg(record_path, ann_path, window_pre=0.2, window_post=0.4):\n",
        "    \"\"\"Load, filter, detect R-peaks, and segment beats with labels.\"\"\"\n",
        "    try:\n",
        "        # Load ECG\n",
        "        rec = wfdb.rdrecord(record_path)\n",
        "        sig = rec.p_signal[:, 0]  # first channel\n",
        "        fs = rec.fs\n",
        "\n",
        "        # Filter\n",
        "        sig_filtered = bandpass_filter(sig, fs)\n",
        "\n",
        "        # Annotations\n",
        "        ann = wfdb.rdann(ann_path, \"atr\")\n",
        "        r_locs = ann.sample\n",
        "        labels = ann.symbol  # beat labels\n",
        "\n",
        "        # Segment beats\n",
        "        beats, beat_labels = [], []\n",
        "        wp = int(window_pre * fs)\n",
        "        ws = int(window_post * fs)\n",
        "        for r, lbl in zip(r_locs, labels):\n",
        "            start = r - wp\n",
        "            end = r + ws\n",
        "            if start >= 0 and end < len(sig_filtered):\n",
        "                beat = sig_filtered[start:end]\n",
        "                beats.append(beat)\n",
        "                beat_labels.append(lbl)\n",
        "\n",
        "        return np.array(beats), np.array(beat_labels)\n",
        "    except Exception as e:\n",
        "        print(f\" Error in {record_path}: {e}\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 4. Batch process all records\n",
        "# ================================================================\n",
        "all_beats, all_labels = [], []\n",
        "\n",
        "for rec in record_ids:\n",
        "    rec_path = os.path.join(\"data/raw\", rec, rec)\n",
        "    beats, labels = preprocess_ecg(rec_path, rec_path)\n",
        "    if beats.size > 0:\n",
        "        all_beats.append(beats)\n",
        "        all_labels.append(labels)\n",
        "        print(f\" {rec}: {beats.shape[0]} beats extracted\")\n",
        "\n",
        "# Concatenate\n",
        "all_beats = np.vstack(all_beats)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "print(f\"\\n Total beats extracted: {all_beats.shape[0]}\")\n",
        "print(f\"Label distribution: {Counter(all_labels)}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# 5. Balance dataset\n",
        "# ================================================================\n",
        "unique_labels = np.unique(all_labels)\n",
        "balanced_beats, balanced_labels = [], []\n",
        "\n",
        "min_count = min([np.sum(all_labels == lbl) for lbl in unique_labels])\n",
        "print(f\"Balancing dataset to {min_count} samples per class...\")\n",
        "\n",
        "for lbl in unique_labels:\n",
        "    beats_lbl = all_beats[all_labels == lbl]\n",
        "    resampled_beats = resample(beats_lbl, replace=False, n_samples=min_count, random_state=42)\n",
        "    balanced_beats.append(resampled_beats)\n",
        "    balanced_labels.extend([lbl] * min_count)\n",
        "\n",
        "balanced_beats = np.vstack(balanced_beats)\n",
        "balanced_labels = np.array(balanced_labels)\n",
        "\n",
        "print(f\"Final balanced dataset: {balanced_beats.shape[0]} beats\")\n",
        "print(f\"Final label distribution: {Counter(balanced_labels)}\")\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# Save dataset\n",
        "# ================================================================\n",
        "np.save(\"data/processed/beats.npy\", balanced_beats)\n",
        "np.save(\"data/processed/labels.npy\", balanced_labels)\n",
        "\n",
        "print(\"Data saved in data/processed/ (beats.npy & labels.npy)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWEA-FFLQXZt"
      },
      "source": [
        "CNN Model Definition & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEu0jYLbQaWo",
        "outputId": "0b54ef52-111c-4f7a-afce-8b598014c95f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Classes: ['+' '/' 'A' 'F' 'J' 'L' 'N' 'Q' 'R' 'V' 'a' 'f' 'j' 'x' '|' '~']\n",
            "✅ Computed class weights: {0: np.float64(1.0), 1: np.float64(1.0), 2: np.float64(1.0), 3: np.float64(1.0), 4: np.float64(1.0), 5: np.float64(1.0), 6: np.float64(1.0), 7: np.float64(1.0), 8: np.float64(1.0), 9: np.float64(1.0), 10: np.float64(1.0), 11: np.float64(1.0), 12: np.float64(1.0), 13: np.float64(1.0), 14: np.float64(1.0), 15: np.float64(1.0)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ECG-Classifier\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 2.9610"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 577ms/step - accuracy: 0.0132 - loss: 2.9567 - val_accuracy: 0.0500 - val_loss: 2.7718\n",
            "Epoch 2/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.0938 - loss: 2.6820"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.0921 - loss: 2.6934 - val_accuracy: 0.1000 - val_loss: 2.7710\n",
            "Epoch 3/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2344 - loss: 2.5470"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.2105 - loss: 2.5578 - val_accuracy: 0.1500 - val_loss: 2.7697\n",
            "Epoch 4/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.2969 - loss: 2.4132"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.2895 - loss: 2.4341 - val_accuracy: 0.1000 - val_loss: 2.7697\n",
            "Epoch 5/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3438 - loss: 2.3106"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.3026 - loss: 2.3535 - val_accuracy: 0.0500 - val_loss: 2.7697\n",
            "Epoch 6/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3281 - loss: 2.2355"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.3026 - loss: 2.2695 - val_accuracy: 0.0500 - val_loss: 2.7689\n",
            "Epoch 7/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2656 - loss: 2.2712"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.2500 - loss: 2.2871 - val_accuracy: 0.0500 - val_loss: 2.7682\n",
            "Epoch 8/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3438 - loss: 2.2011"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3421 - loss: 2.2181 - val_accuracy: 0.0500 - val_loss: 2.7675\n",
            "Epoch 9/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4219 - loss: 2.1427"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.3947 - loss: 2.1636 - val_accuracy: 0.0500 - val_loss: 2.7668\n",
            "Epoch 10/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3438 - loss: 2.1428"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.3421 - loss: 2.1360 - val_accuracy: 0.0500 - val_loss: 2.7662\n",
            "Epoch 11/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3125 - loss: 2.1037"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.3026 - loss: 2.1080 - val_accuracy: 0.0500 - val_loss: 2.7657\n",
            "Epoch 12/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4375 - loss: 1.9161"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.4079 - loss: 1.9815 - val_accuracy: 0.0500 - val_loss: 2.7652\n",
            "Epoch 13/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4531 - loss: 1.9610"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.4211 - loss: 2.0103 - val_accuracy: 0.0500 - val_loss: 2.7647\n",
            "Epoch 14/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3594 - loss: 1.9986"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3816 - loss: 1.9823 - val_accuracy: 0.0500 - val_loss: 2.7644\n",
            "Epoch 15/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5000 - loss: 1.8369"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.4605 - loss: 1.8958 - val_accuracy: 0.0500 - val_loss: 2.7638\n",
            "Epoch 16/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4844 - loss: 1.7750"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.4737 - loss: 1.7895 - val_accuracy: 0.0500 - val_loss: 2.7635\n",
            "Epoch 17/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4844 - loss: 1.9093"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.4342 - loss: 1.9657 - val_accuracy: 0.0500 - val_loss: 2.7631\n",
            "Epoch 18/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4688 - loss: 1.7557"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.4474 - loss: 1.7517 - val_accuracy: 0.0500 - val_loss: 2.7619\n",
            "Epoch 19/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4375 - loss: 1.7512"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.4737 - loss: 1.7223 - val_accuracy: 0.0500 - val_loss: 2.7607\n",
            "Epoch 20/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.4062 - loss: 1.7902"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.4474 - loss: 1.7765 - val_accuracy: 0.0500 - val_loss: 2.7597\n",
            "Epoch 21/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4688 - loss: 1.6918"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.4605 - loss: 1.7165 - val_accuracy: 0.0500 - val_loss: 2.7589\n",
            "Epoch 22/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5156 - loss: 1.6700"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.5132 - loss: 1.7086 - val_accuracy: 0.0500 - val_loss: 2.7580\n",
            "Epoch 23/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4844 - loss: 1.7088"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.4605 - loss: 1.7021 - val_accuracy: 0.0500 - val_loss: 2.7570\n",
            "Epoch 24/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5312 - loss: 1.5761"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.5132 - loss: 1.6351 - val_accuracy: 0.0500 - val_loss: 2.7562\n",
            "Epoch 25/30\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4062 - loss: 1.6153"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.4211 - loss: 1.6287 - val_accuracy: 0.0500 - val_loss: 2.7554\n",
            "Epoch 26/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5132 - loss: 1.5722 - val_accuracy: 0.0500 - val_loss: 2.7560\n",
            "Epoch 27/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5921 - loss: 1.5715 - val_accuracy: 0.0500 - val_loss: 2.7568\n",
            "Epoch 28/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5658 - loss: 1.5284 - val_accuracy: 0.0500 - val_loss: 2.7569\n",
            "Epoch 29/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5789 - loss: 1.5202 - val_accuracy: 0.0500 - val_loss: 2.7565\n",
            "Epoch 30/30\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.5526 - loss: 1.4659 - val_accuracy: 0.0500 - val_loss: 2.7561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model trained and saved at models/cnn_ecg_final.h5\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# 6. Build and Train 1D-CNN for ECG Beat Classification\n",
        "# ================================================================\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os\n",
        "\n",
        "# ------------------------------\n",
        "# Load processed dataset\n",
        "# ------------------------------\n",
        "X = np.load(\"data/processed/beats.npy\")\n",
        "y = np.load(\"data/processed/labels.npy\")\n",
        "\n",
        "# Add channel dimension for Conv1D\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "# ------------------------------\n",
        "# Encode string labels -> integers\n",
        "# ------------------------------\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)   # e.g., \"/\" -> 0, \"N\" -> 1, \"V\" -> 2\n",
        "\n",
        "# Save mapping for later decoding\n",
        "os.makedirs(\"data/processed\", exist_ok=True)\n",
        "np.save(\"data/processed/label_classes.npy\", encoder.classes_)\n",
        "print(\"Classes:\", encoder.classes_)\n",
        "\n",
        "# ------------------------------\n",
        "# Train-validation split\n",
        "# ------------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y_encoded, stratify=y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = len(np.unique(y_encoded))\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
        "y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=num_classes)\n",
        "\n",
        "# ------------------------------\n",
        "# Handle class imbalance\n",
        "# ------------------------------\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\", classes=np.unique(y_encoded), y=y_encoded\n",
        ")\n",
        "cw_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "print(\"Computed class weights:\", cw_dict)\n",
        "\n",
        "# ------------------------------\n",
        "# Define 1D CNN model\n",
        "# ------------------------------\n",
        "def build_cnn(input_shape, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv1D(32, kernel_size=7, padding=\"same\", activation=\"relu\", input_shape=input_shape),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "        tf.keras.layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "        tf.keras.layers.Conv1D(128, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_cnn(X_train.shape[1:], num_classes)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "# ------------------------------\n",
        "# Train model with callbacks\n",
        "# ------------------------------\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"models/cnn_ecg_best.h5\", save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    validation_data=(X_val, y_val_cat),\n",
        "    epochs=30,\n",
        "    batch_size=64,\n",
        "    class_weight=cw_dict,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# Save final model\n",
        "# ------------------------------\n",
        "model.save(\"models/cnn_ecg_final.h5\")\n",
        "print(\"Model trained and saved at models/cnn_ecg_final.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rNF3O5dQdFs"
      },
      "source": [
        "3. Grad-CAM for Explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WOcngMyyQftW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def grad_cam_1d(model, signal, class_index, layer_name=\"conv1d_2\"):\n",
        "    \"\"\"\n",
        "    Generate Grad-CAM heatmap for 1D CNN input.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained tf.keras model.\n",
        "        signal: 1D numpy array of shape (seq_len,) or (seq_len,1).\n",
        "        class_index: Target class index for explanation.\n",
        "        layer_name: Name of the last conv layer.\n",
        "    Returns:\n",
        "        heatmap (numpy array): Importance weights aligned to signal length.\n",
        "    \"\"\"\n",
        "    # Ensure correct shape: (1, seq_len, 1)\n",
        "    if signal.ndim == 1:\n",
        "        signal = np.expand_dims(signal, axis=-1)\n",
        "    signal = np.expand_dims(signal, axis=0)\n",
        "\n",
        "    # Get the last conv layer\n",
        "    conv_layer = model.get_layer(layer_name)\n",
        "\n",
        "    # Create model: input -> (conv outputs, predictions)\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=model.inputs,\n",
        "        outputs=[conv_layer.output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(signal)\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    # Compute gradients of loss wrt conv outputs\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "\n",
        "    # Global average pooling over channels\n",
        "    weights = tf.reduce_mean(grads, axis=1)  # shape (batch, channels)\n",
        "\n",
        "    # Weighted combination of conv outputs\n",
        "    cam = tf.reduce_sum(tf.multiply(conv_outputs, tf.expand_dims(weights, 1)), axis=-1)\n",
        "\n",
        "    # Normalize heatmap to 0–1\n",
        "    heatmap = tf.maximum(cam, 0).numpy()[0]\n",
        "    heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) + 1e-8)\n",
        "\n",
        "    # Resize to match signal length\n",
        "    heatmap = np.interp(\n",
        "        np.arange(signal.shape[1]),\n",
        "        np.linspace(0, signal.shape[1] - 1, len(heatmap)),\n",
        "        heatmap\n",
        "    )\n",
        "\n",
        "    return heatmap\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
